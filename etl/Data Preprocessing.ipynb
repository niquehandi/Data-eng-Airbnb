{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType, LongType\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d2eadaed25d51b84",
   "metadata": {},
   "source": [
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AirbnbAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session created\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "spark"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfa69e7e55e5cbe6",
   "metadata": {},
   "source": [
    "# Configuration Parameters\n",
    "class Config:\n",
    "    # File paths\n",
    "    LISTINGS_PATH = '../data/listings.csv'\n",
    "    REVIEWS_PATH = '../data/reviews.csv'\n",
    "    OUTPUT_DIR = '../data/'\n",
    "\n",
    "    # Filtering thresholds\n",
    "    MIN_USER_REVIEWS = 3  # Minimum reviews per user\n",
    "    MIN_LISTING_REVIEWS = 5  # Minimum reviews per listing\n",
    "\n",
    "    # Train/test split\n",
    "    TRAIN_RATIO = 0.8\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "config = Config()\n",
    "print(\"Configuration set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fba44e77a9b70fd",
   "metadata": {},
   "source": [
    "# Load Raw Data\n",
    "print(\"Loading data...\")\n",
    "\n",
    "listings_cols = [\n",
    "    'id', 'name', 'description', 'neighbourhood_cleansed',\n",
    "    'latitude', 'longitude', 'property_type', 'room_type',\n",
    "    'accommodates', 'bedrooms', 'beds', 'price',\n",
    "    'minimum_nights', 'number_of_reviews', 'review_scores_rating',\n",
    "    'review_scores_location', 'review_scores_value',\n",
    "    'host_is_superhost', 'instant_bookable', 'picture_url'\n",
    "]\n",
    "\n",
    "reviews_cols = ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
    "\n",
    "listings_raw = pd.read_csv(config.LISTINGS_PATH, usecols=listings_cols)\n",
    "reviews_raw = pd.read_csv(config.REVIEWS_PATH, usecols=reviews_cols)\n",
    "\n",
    "print(f\"✓ Loaded {len(listings_raw):,} listings\")\n",
    "print(f\"✓ Loaded {len(reviews_raw):,} reviews\")\n",
    "print(f\"✓ Unique users: {reviews_raw['reviewer_id'].nunique():,}\")\n",
    "print(f\"✓ Unique listings: {reviews_raw['listing_id'].nunique():,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "386ca7a5631c2992",
   "metadata": {},
   "source": [
    "# Visualize Distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Reviews per user\n",
    "user_review_counts = reviews_raw['reviewer_id'].value_counts()\n",
    "axes[0, 0].hist(user_review_counts, bins=range(1, 7), edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Number of Reviews')\n",
    "axes[0, 0].set_ylabel('Number of Users')\n",
    "axes[0, 0].set_title('Reviews per User Distribution')\n",
    "axes[0, 0].axvline(config.MIN_USER_REVIEWS, color='red', linestyle='--',\n",
    "                   label=f'Threshold: {config.MIN_USER_REVIEWS}')\n",
    "axes[0, 0].set_xlim(1, 6)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Reviews per listing\n",
    "listing_review_counts = reviews_raw['listing_id'].value_counts()\n",
    "axes[0, 1].hist(listing_review_counts, bins=range(1, 26), edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Number of Reviews')\n",
    "axes[0, 1].set_ylabel('Number of Listings')\n",
    "axes[0, 1].set_title('Reviews per Listing Distribution')\n",
    "axes[0, 1].axvline(config.MIN_LISTING_REVIEWS, color='red', linestyle='--',\n",
    "                   label=f'Threshold: {config.MIN_LISTING_REVIEWS}')\n",
    "axes[0, 1].set_xlim(1, 25)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Reviews over time\n",
    "reviews_raw['date'] = pd.to_datetime(reviews_raw['date'])\n",
    "reviews_by_month = reviews_raw.set_index('date').resample('ME').size()\n",
    "axes[1, 0].plot(reviews_by_month[:-1])\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Number of Reviews')\n",
    "axes[1, 0].set_title('Reviews Over Time')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Price distribution\n",
    "axes[1, 1].hist(listings_raw['price'].str.replace('$', '').str.replace(',', '').astype(float).dropna().clip(0, 670),\n",
    "                bins=50, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Price ($)')\n",
    "axes[1, 1].set_ylabel('Number of Listings')\n",
    "axes[1, 1].set_title('Price Distribution (capped at $670)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Users with ≥{config.MIN_USER_REVIEWS} reviews: {(user_review_counts >= config.MIN_USER_REVIEWS).sum():,}\")\n",
    "print(\n",
    "    f\"Listings with ≥{config.MIN_LISTING_REVIEWS} reviews: {(listing_review_counts >= config.MIN_LISTING_REVIEWS).sum():,}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78309914e21c514d",
   "metadata": {},
   "source": [
    "# Clean Listings Data\n",
    "listings_clean = listings_raw.copy()\n",
    "\n",
    "# 1. Clean price\n",
    "listings_clean['price'] = listings_clean['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# 2. Handle missing values\n",
    "\n",
    "# listings_clean['review_scores_rating'].fillna(\n",
    "#     listings_clean['review_scores_rating'].median(),\n",
    "#     inplace=True\n",
    "# )\n",
    "\n",
    "listings_clean['bedrooms'] = listings_clean['bedrooms'].fillna(0)\n",
    "listings_clean['beds'] = listings_clean['beds'].fillna(0)\n",
    "\n",
    "# 3. Convert boolean columns\n",
    "listings_clean['host_is_superhost'] = listings_clean['host_is_superhost'].map({'t': True, 'f': False}).fillna(False)\n",
    "listings_clean['instant_bookable'] = listings_clean['instant_bookable'].map({'t': True, 'f': False}).fillna(False)\n",
    "\n",
    "# 4. Rename id column for clarity\n",
    "listings_clean.rename(columns={'id': 'listing_id'}, inplace=True)\n",
    "\n",
    "print(\"✓ Listings data cleaned\")\n",
    "print(f\"Price range: ${listings_clean['price'].min():.2f} - ${listings_clean['price'].max():.2f}\")\n",
    "print(f\"Median price: ${listings_clean['price'].median():.2f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1a8b21a6a3fc9b7",
   "metadata": {},
   "source": [
    "# Cell 9: Apply Filtering\n",
    "print(\"Applying filters...\")\n",
    "print(f\"Original: {len(reviews_raw):,} reviews\")\n",
    "\n",
    "# Count reviews per user and listing\n",
    "user_counts = reviews_raw['reviewer_id'].value_counts()\n",
    "listing_counts = reviews_raw['listing_id'].value_counts()\n",
    "\n",
    "# Identify active users and popular listings\n",
    "active_users = user_counts[user_counts >= config.MIN_USER_REVIEWS].index\n",
    "popular_listings = listing_counts[listing_counts >= config.MIN_LISTING_REVIEWS].index\n",
    "\n",
    "print(f\"Active users (≥{config.MIN_USER_REVIEWS} reviews): {len(active_users):,}\")\n",
    "print(f\"Popular listings (≥{config.MIN_LISTING_REVIEWS} reviews): {len(popular_listings):,}\")\n",
    "\n",
    "# Apply filters\n",
    "reviews_filtered = reviews_raw[\n",
    "    reviews_raw['reviewer_id'].isin(active_users) &\n",
    "    reviews_raw['listing_id'].isin(popular_listings)\n",
    "    ].copy()\n",
    "\n",
    "reviews_filtered = reviews_filtered.sort_values('date').drop_duplicates(\n",
    "    subset=['reviewer_id', 'listing_id'],\n",
    "    keep='last'\n",
    ")\n",
    "\n",
    "print(f\"Filtered: {len(reviews_filtered):,} reviews\")\n",
    "print(f\"Reduction: {(1 - len(reviews_filtered) / len(reviews_raw)) * 100:.1f}%\")\n",
    "\n",
    "# Update listings to only include those with reviews\n",
    "listings_filtered = listings_clean[\n",
    "    listings_clean['listing_id'].isin(reviews_filtered['listing_id'])\n",
    "].copy()\n",
    "\n",
    "print(f\"Listings after filtering: {len(listings_filtered):,}\")\n",
    "\n",
    "# Calculate sparsity\n",
    "n_users = reviews_filtered['reviewer_id'].nunique()\n",
    "n_listings = reviews_filtered['listing_id'].nunique()\n",
    "n_interactions = len(reviews_filtered)\n",
    "sparsity = 1 - (n_interactions / (n_users * n_listings))\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Users: {n_users:,}\")\n",
    "print(f\"  Listings: {n_listings:,}\")\n",
    "print(f\"  Interactions: {n_interactions:,}\")\n",
    "print(f\"  Sparsity: {sparsity * 100:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Construct Ratings\n",
    "\n",
    "def construct_continuous_ratings(reviews_df):\n",
    "    \"\"\"\n",
    "    Airbnb implicit rating construction from review engagement signals\n",
    "    \"\"\"\n",
    "    df = reviews_df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['review_length'] = df['comments'].fillna('').astype(str).str.len()\n",
    "\n",
    "    max_date = df['date'].max()\n",
    "    df['days_ago'] = (max_date - df['date']).dt.days\n",
    "\n",
    "    # User engagement: How active is this reviewer?\n",
    "    user_activity = df.groupby('reviewer_id').size().reset_index(name='user_review_count')\n",
    "    df = df.merge(user_activity, on='reviewer_id', how='left')\n",
    "\n",
    "    # Listing popularity: How many reviews does this property have?\n",
    "    listing_popularity = df.groupby('listing_id').size().reset_index(name='listing_review_count')\n",
    "    df = df.merge(listing_popularity, on='listing_id', how='left')\n",
    "\n",
    "    # Feature engineering\n",
    "    df['recency_score'] = np.exp(-df['days_ago'] / 365)  # 1-year decay (faster for travel)\n",
    "    df['length_score'] = np.log1p(df['review_length'])\n",
    "    df['user_credibility'] = np.log1p(df['user_review_count'])  # Experienced reviewers more valuable\n",
    "    df['listing_signal'] = np.log1p(df['listing_review_count'])  # Popular listings get boost\n",
    "\n",
    "    # Normalize to 0-1\n",
    "    df['recency_norm'] = df['recency_score']  # Already 0-1\n",
    "    df['length_norm'] = df['length_score'] / df['length_score'].max()\n",
    "    df['credibility_norm'] = df['user_credibility'] / df['user_credibility'].max()\n",
    "    df['popularity_norm'] = df['listing_signal'] / df['listing_signal'].max()\n",
    "\n",
    "    # Airbnb-optimized weights\n",
    "    df['composite_score'] = (\n",
    "            df['recency_norm'] * 0.5 +  # Highest: Properties change quickly\n",
    "            df['length_norm'] * 0.3 +  # Strong signal: Detailed = satisfied\n",
    "            df['credibility_norm'] * 0.1 +  # Moderate: Trust experienced reviewers\n",
    "            df['popularity_norm'] * 0.1  # Moderate: Popular listings have reasons\n",
    "    )\n",
    "\n",
    "    # Map to 1-5 scale\n",
    "    df['rating'] = (df['composite_score'].rank(method='average', pct=True) * 4 + 1).round(2)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "reviews_with_ratings = construct_continuous_ratings(reviews_filtered)\n",
    "\n",
    "print(f\"\\nFiltered Rating distribution:\")\n",
    "print(reviews_with_ratings['rating'].describe())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(reviews_with_ratings['rating'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Rating')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(reviews_with_ratings['rating'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {reviews_with_ratings[\"rating\"].mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Value counts\n",
    "rating_counts = reviews_with_ratings['rating'].value_counts().sort_index()\n",
    "axes[1].bar(rating_counts.index, rating_counts.values, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Rating')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Rating Value Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cd1203a64b2bdb51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create Final Interactions DataFrame\n",
    "interactions = reviews_with_ratings[[\n",
    "    'reviewer_id',\n",
    "    'listing_id',\n",
    "    'rating',\n",
    "    'date'\n",
    "]].copy()\n",
    "\n",
    "# Remove duplicates (keep most recent review if user reviewed same listing multiple times)\n",
    "# interactions = interactions.sort_values('date').drop_duplicates(\n",
    "#     subset=['reviewer_id', 'listing_id'],\n",
    "#     keep='last'\n",
    "# )\n",
    "\n",
    "print(f\"✓ Interactions DataFrame created\")\n",
    "print(f\"Shape: {interactions.shape}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(interactions.head())"
   ],
   "id": "48015566a5f5dedc"
  },
  {
   "cell_type": "code",
   "id": "44d99d08472120a9",
   "metadata": {},
   "source": [
    "interactions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a633797741fd62a",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "\n",
    "# Split by user (ensure each user appears in both train and test)\n",
    "train_data, test_data = train_test_split(\n",
    "    interactions,\n",
    "    test_size=(1 - config.TRAIN_RATIO),\n",
    "    random_state=config.RANDOM_SEED,\n",
    "    stratify=None  # Random split\n",
    ")\n",
    "\n",
    "print(f\"✓ Data split into train/test\")\n",
    "print(f\"Training set: {len(train_data):,} interactions\")\n",
    "print(f\"Test set: {len(test_data):,} interactions\")\n",
    "print(\n",
    "    f\"Split ratio: {len(train_data) / len(interactions) * 100:.1f}% / {len(test_data) / len(interactions) * 100:.1f}%\")\n",
    "\n",
    "# Verify users/listings overlap\n",
    "train_users = set(train_data['reviewer_id'])\n",
    "test_users = set(test_data['reviewer_id'])\n",
    "train_listings = set(train_data['listing_id'])\n",
    "test_listings = set(test_data['listing_id'])\n",
    "\n",
    "print(f\"\\nUsers in both sets: {len(train_users & test_users):,}\")\n",
    "print(f\"Listings in both sets: {len(train_listings & test_listings):,}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1be72de331484fa",
   "metadata": {},
   "source": [
    "# Convert to Spark DataFrames\n",
    "\n",
    "# Convert interactions to Spark\n",
    "train_spark = spark.createDataFrame(train_data)\n",
    "test_spark = spark.createDataFrame(test_data)\n",
    "\n",
    "# Convert listings to Spark\n",
    "listings_spark = spark.createDataFrame(listings_filtered)\n",
    "\n",
    "print(\"✓ Converted to Spark DataFrames\")\n",
    "print(\"\\nTrain schema:\")\n",
    "train_spark.printSchema()\n",
    "print(f\"\\nTrain count: {train_spark.count():,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a866d03d5580392",
   "metadata": {},
   "source": [
    "# Create Integer IDs for ALS\n",
    "\n",
    "# 1. Combine train and test for indexer fitting\n",
    "combined_ids = train_spark.select(\"reviewer_id\", \"listing_id\").union(\n",
    "    test_spark.select(\"reviewer_id\", \"listing_id\")\n",
    ").distinct()\n",
    "\n",
    "# 2. Fit indexers on ALL unique IDs\n",
    "user_indexer = StringIndexer(inputCol=\"reviewer_id\", outputCol=\"user_id\", )\n",
    "item_indexer = StringIndexer(inputCol=\"listing_id\", outputCol=\"item_id\", )\n",
    "\n",
    "user_indexer_model = user_indexer.fit(combined_ids.select(\"reviewer_id\"))\n",
    "item_indexer_model = item_indexer.fit(combined_ids.select(\"listing_id\"))\n",
    "\n",
    "# 3. Transform train and test\n",
    "train_indexed = user_indexer_model.transform(train_spark)\n",
    "train_indexed = item_indexer_model.transform(train_indexed)\n",
    "\n",
    "test_indexed = user_indexer_model.transform(test_spark)\n",
    "test_indexed = item_indexer_model.transform(test_indexed)\n",
    "\n",
    "# Cast to appropriate types\n",
    "train_final = train_indexed.select(\n",
    "    col(\"user_id\").cast(LongType()),\n",
    "    col(\"item_id\").cast(LongType()),\n",
    "    col(\"rating\").cast(FloatType()),\n",
    "    col(\"reviewer_id\"),  # Keep original IDs for reference\n",
    "    col(\"listing_id\")\n",
    ")\n",
    "\n",
    "test_final = test_indexed.select(\n",
    "    col(\"user_id\").cast(LongType()),\n",
    "    col(\"item_id\").cast(LongType()),\n",
    "    col(\"rating\").cast(FloatType()),\n",
    "    col(\"reviewer_id\"),\n",
    "    col(\"listing_id\")\n",
    ")\n",
    "\n",
    "print(\"✓ User and item IDs indexed\")\n",
    "print(\"\\nFinal train schema:\")\n",
    "train_final.printSchema()\n",
    "print(\"\\nSample:\")\n",
    "train_final.show(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fb69e60f89e1b5b",
   "metadata": {},
   "source": [
    "# Save ID Mappings for Later Use\n",
    "# Extract user ID mapping\n",
    "user_mapping = train_indexed.select(\"reviewer_id\", \"user_id\").distinct().toPandas()\n",
    "user_mapping.to_csv(f'{config.OUTPUT_DIR}user_id_mapping.csv', index=False)\n",
    "\n",
    "# Extract item ID mapping\n",
    "item_mapping = train_indexed.select(\"listing_id\", \"item_id\").distinct().toPandas()\n",
    "item_mapping.to_csv(f'{config.OUTPUT_DIR}item_id_mapping.csv', index=False)\n",
    "\n",
    "print(f\"✓ Saved user mapping: {len(user_mapping):,} users\")\n",
    "print(f\"✓ Saved item mapping: {len(item_mapping):,} items\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be35cb802ddc8011",
   "metadata": {},
   "source": [
    "# Cell 15: Save All Processed Data\n",
    "\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save Spark DataFrames as Parquet\n",
    "train_final.write.mode('overwrite').parquet(f'{config.OUTPUT_DIR}train.parquet')\n",
    "test_final.write.mode('overwrite').parquet(f'{config.OUTPUT_DIR}test.parquet')\n",
    "listings_spark.write.mode('overwrite').parquet(f'{config.OUTPUT_DIR}listings.parquet')\n",
    "\n",
    "# Also save as CSV for easy inspection\n",
    "train_final.limit(1000).toPandas().to_csv(f'{config.OUTPUT_DIR}train_sample.csv', index=False)\n",
    "listings_filtered.to_csv(f'{config.OUTPUT_DIR}listings_metadata.csv', index=False)\n",
    "\n",
    "print(\"✓ All data saved successfully\")\n",
    "print(f\"\\nFiles saved to: {config.OUTPUT_DIR}\")\n",
    "print(\"  - train.parquet\")\n",
    "print(\"  - test.parquet\")\n",
    "print(\"  - listings.parquet\")\n",
    "print(\"  - user_id_mapping.csv\")\n",
    "print(\"  - item_id_mapping.csv\")\n",
    "print(\"  - train_sample.csv\")\n",
    "print(\"  - listings_metadata.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
