{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Config:\n",
    "    TRAIN_PATH = '../data/train.parquet'\n",
    "    TEST_PATH = '../data/test.parquet'\n",
    "    MODEL_PATH = '../data/als_model_baseline'\n",
    "\n",
    "    # Baseline ALS Parameters\n",
    "    RANK = 20  # Number of latent factors\n",
    "    MAX_ITER = 10  # Maximum iterations\n",
    "    REG_PARAM = 0.1  # Regularization parameter\n",
    "    COLD_START = 'drop'  # Drop rows with NaN predictions during eval\n",
    "\n",
    "\n",
    "config = Config()"
   ],
   "id": "894be9d61d17e358",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AirbnbALS_Baseline\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Session created. Version: {spark.version}\")"
   ],
   "id": "a195b02a8d88f1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "if not os.path.exists(config.TRAIN_PATH) or not os.path.exists(config.TEST_PATH):\n",
    "    raise FileNotFoundError(\"Train/Test data not found. Please run the previous data prep step first.\")\n",
    "\n",
    "train_data = spark.read.parquet(config.TRAIN_PATH)\n",
    "test_data = spark.read.parquet(config.TEST_PATH)\n",
    "\n",
    "# Cache data for faster iteration\n",
    "train_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "print(f\"Train count: {train_data.count():,}\")\n",
    "print(f\"Test count:  {test_data.count():,}\")"
   ],
   "id": "781786c7957e2e01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Implement ALS Model\n",
    "print(\"\\nInitializing ALS model...\")\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"item_id\",\n",
    "    ratingCol=\"rating\",\n",
    "    rank=config.RANK,\n",
    "    maxIter=config.MAX_ITER,\n",
    "    regParam=config.REG_PARAM,\n",
    "    coldStartStrategy=config.COLD_START,  # Critical for evaluation\n",
    "    nonnegative=True  # Ratings are 1-5, so forces positive factors\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model (this may take a moment)...\")\n",
    "model = als.fit(train_data)\n",
    "\n",
    "print(\"âœ“ Model trained successfully\")"
   ],
   "id": "eee23604d836831f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate Predictions\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "\n",
    "# Transform test data to get predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"Sample Predictions:\")\n",
    "predictions.select(\n",
    "    \"user_id\",\n",
    "    \"item_id\",\n",
    "    \"rating\",\n",
    "    round(\"prediction\", 2).alias(\"prediction\")\n",
    ").show(10)"
   ],
   "id": "59f53ed3907e2970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Calculating RMSE...\")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "# Contextual Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"On average, the model's prediction is off by {rmse:.2f} stars.\")\n",
    "print(f\"For a 5-star scale, an RMSE below 1.0 is generally considered acceptable for a baseline.\")"
   ],
   "id": "60def28480728a43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nLearned User Factors (First 5):\")\n",
    "model.userFactors.show(5, truncate=False)\n",
    "\n",
    "# Save the model for future use\n",
    "print(f\"Saving model to {config.MODEL_PATH}...\")\n",
    "model.write().overwrite().save(config.MODEL_PATH)"
   ],
   "id": "948033f970bd6b5e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
