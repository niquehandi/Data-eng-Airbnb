{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, round, stddev, min as spark_min, max as spark_max\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "894be9d61d17e358",
   "metadata": {},
   "source": [
    "class Config:\n",
    "    TRAIN_PATH = '../data/train.parquet'\n",
    "    TEST_PATH = '../data/test.parquet'\n",
    "    LISTINGS_PATH = '../data/listings.parquet'\n",
    "    MODEL_PATH = '../data/xgboost_model_baseline'\n",
    "\n",
    "    # Optimized XGBoost Parameters\n",
    "    N_ESTIMATORS = 200  # Increased for better learning\n",
    "    MAX_DEPTH = 5  # Reduced to prevent overfitting\n",
    "    LEARNING_RATE = 0.05  # Reduced for better convergence\n",
    "    SUBSAMPLE = 0.85\n",
    "    COL_SAMPLE_BY_TREE = 0.85\n",
    "    MIN_CHILD_WEIGHT = 3  # Regularization\n",
    "    GAMMA = 0.1  # Minimum loss reduction\n",
    "    REG_ALPHA = 0.1  # L1 regularization\n",
    "    REG_LAMBDA = 1.0  # L2 regularization\n",
    "    VALIDATION_SIZE = 0.2  # Validation set size for monitoring\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "config = Config()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a195b02a8d88f1ed",
   "metadata": {},
   "source": [
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AirbnbXGBoost_Baseline\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Session created. Version: {spark.version}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "781786c7957e2e01",
   "metadata": {},
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "if not os.path.exists(config.TRAIN_PATH) or not os.path.exists(config.TEST_PATH):\n",
    "    raise FileNotFoundError(\"Train/Test data not found. Please run the previous data prep step first.\")\n",
    "\n",
    "if not os.path.exists(config.LISTINGS_PATH):\n",
    "    raise FileNotFoundError(\"Listings data not found. Please run the previous data prep step first.\")\n",
    "\n",
    "# Load Spark DataFrames\n",
    "train_spark = spark.read.parquet(config.TRAIN_PATH)\n",
    "test_spark = spark.read.parquet(config.TEST_PATH)\n",
    "listings_spark = spark.read.parquet(config.LISTINGS_PATH)\n",
    "\n",
    "# Cache for faster iteration\n",
    "train_spark.cache()\n",
    "test_spark.cache()\n",
    "listings_spark.cache()\n",
    "\n",
    "print(f\"Train count: {train_spark.count():,}\")\n",
    "print(f\"Test count:  {test_spark.count():,}\")\n",
    "print(f\"Listings count: {listings_spark.count():,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eee23604d836831f",
   "metadata": {},
   "source": [
    "# Enhanced Feature Engineering (NO DATA LEAKAGE)\n",
    "print(\"\\nCreating CLEAN features for XGBoost (no target-derived features)...\")\n",
    "\n",
    "# CLEAN User features - counts only (NO rating-based statistics)\n",
    "print(\"  - Computing clean user statistics (counts only)...\")\n",
    "user_stats = train_spark.groupBy(\"user_id\").agg(\n",
    "    count(\"item_id\").alias(\"user_review_count\")\n",
    "    # REMOVED: avg(\"rating\"), stddev(\"rating\"), min(\"rating\"), max(\"rating\")\n",
    "    # These caused data leakage as they were derived from the target variable\n",
    ").withColumnRenamed(\"user_id\", \"user_id_stats\")\n",
    "\n",
    "# CLEAN Item features - counts only (NO rating-based statistics)\n",
    "print(\"  - Computing clean item statistics (counts only)...\")\n",
    "item_stats = train_spark.groupBy(\"item_id\").agg(\n",
    "    count(\"user_id\").alias(\"item_review_count\")\n",
    "    # REMOVED: avg(\"rating\"), stddev(\"rating\"), min(\"rating\"), max(\"rating\")\n",
    "    # These caused data leakage as they were derived from the target variable\n",
    ").withColumnRenamed(\"item_id\", \"item_id_stats\")\n",
    "\n",
    "# 3. Join clean user and item stats to train data\n",
    "print(\"  - Joining clean features to train data...\")\n",
    "train_with_features = train_spark \\\n",
    "    .join(user_stats, train_spark.user_id == user_stats.user_id_stats, \"left\") \\\n",
    "    .join(item_stats, train_spark.item_id == item_stats.item_id_stats, \"left\") \\\n",
    "    .drop(\"user_id_stats\", \"item_id_stats\")\n",
    "\n",
    "# 4. Join listings features\n",
    "print(\"  - Joining listings metadata...\")\n",
    "train_with_features = train_with_features \\\n",
    "    .join(listings_spark, train_with_features.listing_id == listings_spark.listing_id, \"left\")\n",
    "\n",
    "# 5. Apply same feature engineering to test data\n",
    "print(\"  - Applying clean features to test data...\")\n",
    "test_with_features = test_spark \\\n",
    "    .join(user_stats, test_spark.user_id == user_stats.user_id_stats, \"left\") \\\n",
    "    .join(item_stats, test_spark.item_id == item_stats.item_id_stats, \"left\") \\\n",
    "    .drop(\"user_id_stats\", \"item_id_stats\") \\\n",
    "    .join(listings_spark, test_spark.listing_id == listings_spark.listing_id, \"left\")\n",
    "\n",
    "print(\"âœ“ Clean feature engineering complete (NO DATA LEAKAGE)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59f53ed3907e2970",
   "metadata": {},
   "source": [
    "# Prepare data for XGBoost (NO DATA LEAKAGE)\n",
    "print(\"\\nPreparing data for XGBoost...\")\n",
    "\n",
    "# Convert to Pandas for XGBoost\n",
    "print(\"  - Converting to Pandas DataFrames...\")\n",
    "train_df = train_with_features.toPandas()\n",
    "test_df = test_with_features.toPandas()\n",
    "\n",
    "print(f\"  - Train shape: {train_df.shape}\")\n",
    "print(f\"  - Test shape: {test_df.shape}\")\n",
    "\n",
    "# CLEAN feature columns - NO target-derived statistics\n",
    "# REMOVED: user_avg_rating, user_rating_std, user_min_rating, user_max_rating\n",
    "# REMOVED: item_avg_rating, item_rating_std, item_min_rating, item_max_rating\n",
    "feature_cols = [\n",
    "    'user_id', 'item_id',\n",
    "    'user_review_count',  # Count only (not rating-based)\n",
    "    'item_review_count',  # Count only (not rating-based)\n",
    "    'price', 'accommodates', 'bedrooms', 'beds',\n",
    "    'minimum_nights', 'number_of_reviews',\n",
    "    'review_scores_rating', 'review_scores_location', 'review_scores_value',  # From Airbnb (not our target)\n",
    "    'latitude', 'longitude'\n",
    "]\n",
    "\n",
    "# Handle categorical columns\n",
    "categorical_cols = ['property_type', 'room_type', 'neighbourhood_cleansed']\n",
    "label_encoders = {}\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    if col_name in train_df.columns:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([train_df[col_name].fillna('unknown'),\n",
    "                              test_df[col_name].fillna('unknown')])\n",
    "        le.fit(combined)\n",
    "        train_df[f'{col_name}_encoded'] = le.transform(train_df[col_name].fillna('unknown'))\n",
    "        test_df[f'{col_name}_encoded'] = le.transform(test_df[col_name].fillna('unknown'))\n",
    "        label_encoders[col_name] = le\n",
    "        feature_cols.append(f'{col_name}_encoded')\n",
    "\n",
    "# Handle boolean columns\n",
    "bool_cols = ['host_is_superhost', 'instant_bookable']\n",
    "for col_name in bool_cols:\n",
    "    if col_name in train_df.columns:\n",
    "        train_df[col_name] = train_df[col_name].astype(float).fillna(0)\n",
    "        test_df[col_name] = test_df[col_name].astype(float).fillna(0)\n",
    "        feature_cols.append(col_name)\n",
    "\n",
    "# Create derived features (CLEAN - no rating-based)\n",
    "print(\"  - Creating clean derived features...\")\n",
    "\n",
    "# Price per person\n",
    "train_df['price_per_person'] = train_df['price'] / (train_df['accommodates'] + 1e-6)\n",
    "test_df['price_per_person'] = test_df['price'] / (test_df['accommodates'] + 1e-6)\n",
    "feature_cols.append('price_per_person')\n",
    "\n",
    "# Bedroom ratio\n",
    "train_df['bedroom_ratio'] = train_df['bedrooms'] / (train_df['accommodates'] + 1e-6)\n",
    "test_df['bedroom_ratio'] = test_df['bedrooms'] / (test_df['accommodates'] + 1e-6)\n",
    "feature_cols.append('bedroom_ratio')\n",
    "\n",
    "# Bed ratio\n",
    "train_df['bed_ratio'] = train_df['beds'] / (train_df['accommodates'] + 1e-6)\n",
    "test_df['bed_ratio'] = test_df['beds'] / (test_df['accommodates'] + 1e-6)\n",
    "feature_cols.append('bed_ratio')\n",
    "\n",
    "# Review score composite (from AIRBNB scores - not our constructed ratings!)\n",
    "train_df['review_score_composite'] = (\n",
    "        train_df['review_scores_rating'].fillna(0) * 0.5 +\n",
    "        train_df['review_scores_location'].fillna(0) * 0.3 +\n",
    "        train_df['review_scores_value'].fillna(0) * 0.2\n",
    ")\n",
    "test_df['review_score_composite'] = (\n",
    "        test_df['review_scores_rating'].fillna(0) * 0.5 +\n",
    "        test_df['review_scores_location'].fillna(0) * 0.3 +\n",
    "        test_df['review_scores_value'].fillna(0) * 0.2\n",
    ")\n",
    "feature_cols.append('review_score_composite')\n",
    "\n",
    "# NO LEAKY INTERACTION FEATURES\n",
    "# REMOVED: user_avg_x_item_avg, user_avg_x_price_norm, item_avg_x_review_score\n",
    "# These were derived from target-based statistics\n",
    "\n",
    "# Select only available features\n",
    "available_features = [f for f in feature_cols if f in train_df.columns]\n",
    "print(f\"  - Using {len(available_features)} CLEAN features (no data leakage)\")\n",
    "\n",
    "# Better missing value handling using median\n",
    "print(\"  - Handling missing values with median imputation...\")\n",
    "numeric_features = [f for f in available_features if f not in ['user_id', 'item_id']]\n",
    "for col in numeric_features:\n",
    "    if col in train_df.columns:\n",
    "        median_val = train_df[col].median()\n",
    "        if pd.notna(median_val):\n",
    "            train_df[col] = train_df[col].fillna(median_val)\n",
    "            test_df[col] = test_df[col].fillna(median_val)\n",
    "        else:\n",
    "            train_df[col] = train_df[col].fillna(0)\n",
    "            test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "# Prepare X and y\n",
    "X_train = train_df[available_features]\n",
    "y_train = train_df['rating'].values\n",
    "X_test = test_df[available_features]\n",
    "y_test = test_df['rating'].values\n",
    "\n",
    "print(\"âœ“ Data prepared for XGBoost (NO DATA LEAKAGE)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd9bafa9",
   "metadata": {},
   "source": [
    "# Hyperparameter Grid Search with Cross-Validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPERPARAMETER TUNING WITH CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "# Full grid (comprehensive but slower)\n",
    "param_grid_full = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.85, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.85, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Smaller grid for faster initial search\n",
    "param_grid_small = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Base model for grid search\n",
    "base_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Configuration for search\n",
    "USE_RANDOMIZED_SEARCH = True  # Set to False for full grid search\n",
    "N_ITER_RANDOM = 30  # Number of random combinations to try\n",
    "CV_FOLDS = 5  # Number of cross-validation folds\n",
    "USE_SMALL_GRID = True  # Use smaller grid for faster search\n",
    "\n",
    "param_grid = param_grid_small if USE_SMALL_GRID else param_grid_full\n",
    "\n",
    "print(f\"\\nSearch Configuration:\")\n",
    "print(f\"  - Method: {'Randomized Search' if USE_RANDOMIZED_SEARCH else 'Grid Search'}\")\n",
    "print(f\"  - CV Folds: {CV_FOLDS}\")\n",
    "print(f\"  - Grid Size: {'Small' if USE_SMALL_GRID else 'Full'}\")\n",
    "if USE_RANDOMIZED_SEARCH:\n",
    "    print(f\"  - Random Iterations: {N_ITER_RANDOM}\")\n",
    "print(f\"  - Training samples: {X_train.shape[0]:,}\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nStarting search at {start_time.strftime('%H:%M:%S')}...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "if USE_RANDOMIZED_SEARCH:\n",
    "    # Randomized Search - faster, good for initial exploration\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=N_ITER_RANDOM,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=CV_FOLDS,\n",
    "        verbose=2,\n",
    "        random_state=config.RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    # Full Grid Search - exhaustive but slower\n",
    "    search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=CV_FOLDS,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Fit the search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\nâœ“ Search completed in {duration:.1f} seconds ({duration / 60:.1f} minutes)\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7588286c",
   "metadata": {},
   "source": [
    "# Display Cross-Validation Results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nðŸ“Š BEST PARAMETERS:\")\n",
    "print(\"-\" * 40)\n",
    "for param, value in search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Best CV score\n",
    "best_cv_rmse = -search.best_score_\n",
    "print(f\"\\nðŸ“ˆ BEST CV RMSE: {best_cv_rmse:.4f}\")\n",
    "\n",
    "# Get cross-validation results dataframe\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results['mean_rmse'] = -cv_results['mean_test_score']\n",
    "cv_results['std_rmse'] = cv_results['std_test_score']\n",
    "\n",
    "# Sort by performance\n",
    "cv_results_sorted = cv_results.sort_values('mean_rmse').reset_index(drop=True)\n",
    "\n",
    "# Display top 10 configurations\n",
    "print(\"\\nðŸ† TOP 10 CONFIGURATIONS:\")\n",
    "print(\"-\" * 60)\n",
    "top_10 = cv_results_sorted[['params', 'mean_rmse', 'std_rmse', 'rank_test_score']].head(10)\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
    "    print(f\"  RMSE: {row['mean_rmse']:.4f} (Â±{row['std_rmse']:.4f})\")\n",
    "    params_str = ', '.join([f\"{k}={v}\" for k, v in row['params'].items()])\n",
    "    print(f\"  Params: {params_str}\")\n",
    "\n",
    "# Cross-validation score distribution for best model\n",
    "print(\"\\nðŸ“‰ CV FOLD SCORES (Best Model):\")\n",
    "print(\"-\" * 40)\n",
    "best_idx = search.best_index_\n",
    "for fold in range(CV_FOLDS):\n",
    "    fold_score = -cv_results.loc[best_idx, f'split{fold}_test_score']\n",
    "    print(f\"  Fold {fold + 1}: RMSE = {fold_score:.4f}\")\n",
    "print(f\"  Mean:   RMSE = {best_cv_rmse:.4f}\")\n",
    "print(f\"  Std:    Â±{cv_results.loc[best_idx, 'std_test_score']:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af4a872d",
   "metadata": {},
   "source": [
    "# Train Final Model with Optimal Hyperparameters\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING FINAL MODEL WITH OPTIMAL PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a new model with best params\n",
    "optimal_model = xgb.XGBRegressor(\n",
    "    **search.best_params_,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on full training data\n",
    "print(\"\\nTraining on full training set...\")\n",
    "optimal_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_optimal = optimal_model.predict(X_test)\n",
    "y_pred_optimal = np.clip(y_pred_optimal, 1.0, 5.0)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimal))\n",
    "test_mae = np.mean(np.abs(y_test - y_pred_optimal))\n",
    "\n",
    "print(f\"\\nâœ“ Final Model Performance:\")\n",
    "print(f\"  - Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  - Test MAE:  {test_mae:.4f}\")\n",
    "print(f\"  - CV RMSE:   {best_cv_rmse:.4f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_rmse = 0.905  # Previous baseline\n",
    "print(f\"\\nðŸ“Š Comparison with Baseline:\")\n",
    "print(f\"  - Baseline RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"  - Optimized RMSE: {test_rmse:.4f}\")\n",
    "improvement = (baseline_rmse - test_rmse) / baseline_rmse * 100\n",
    "if improvement > 0:\n",
    "    print(f\"  - Improvement: {improvement:.2f}% better âœ“\")\n",
    "else:\n",
    "    print(f\"  - Change: {-improvement:.2f}% worse\")\n",
    "\n",
    "# Use this as the final model\n",
    "model = optimal_model\n",
    "y_pred = y_pred_optimal\n",
    "rmse = test_rmse\n",
    "mae = test_mae\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec8a16fa",
   "metadata": {},
   "source": [
    "# Document and Save Optimal Configuration\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOCUMENTING OPTIMAL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Update model path for optimized model\n",
    "optimized_model_path = '../data/xgboost_model_optimized'\n",
    "os.makedirs(optimized_model_path, exist_ok=True)\n",
    "\n",
    "# Create comprehensive documentation\n",
    "optimal_config = {\n",
    "    'search_info': {\n",
    "        'method': 'RandomizedSearchCV' if USE_RANDOMIZED_SEARCH else 'GridSearchCV',\n",
    "        'cv_folds': CV_FOLDS,\n",
    "        'n_iterations': N_ITER_RANDOM if USE_RANDOMIZED_SEARCH else 'full_grid',\n",
    "        'scoring': 'neg_root_mean_squared_error',\n",
    "        'search_duration_seconds': duration,\n",
    "        'grid_type': 'small' if USE_SMALL_GRID else 'full'\n",
    "    },\n",
    "    'optimal_hyperparameters': search.best_params_,\n",
    "    'cross_validation_results': {\n",
    "        'mean_cv_rmse': float(best_cv_rmse),\n",
    "        'std_cv_rmse': float(cv_results.loc[best_idx, 'std_test_score']),\n",
    "        'fold_scores': [float(-cv_results.loc[best_idx, f'split{i}_test_score']) for i in range(CV_FOLDS)]\n",
    "    },\n",
    "    'test_performance': {\n",
    "        'rmse': float(test_rmse),\n",
    "        'mae': float(test_mae),\n",
    "        'baseline_rmse': baseline_rmse,\n",
    "        'improvement_percent': float(improvement)\n",
    "    },\n",
    "    'feature_info': {\n",
    "        'n_features': len(available_features),\n",
    "        'feature_names': available_features\n",
    "    },\n",
    "    'training_info': {\n",
    "        'n_train_samples': int(X_train.shape[0]),\n",
    "        'n_test_samples': int(X_test.shape[0]),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save optimal configuration\n",
    "optimal_config_path = f\"{optimized_model_path}/optimal_config.json\"\n",
    "with open(optimal_config_path, 'w') as f:\n",
    "    json.dump(optimal_config, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Optimal configuration saved to: {optimal_config_path}\")\n",
    "\n",
    "# Print the optimal configuration for easy copy-paste\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMAL CONFIG CLASS (Copy to your notebook)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "class OptimalConfig:\n",
    "    TRAIN_PATH = '../data/train.parquet'\n",
    "    TEST_PATH = '../data/test.parquet'\n",
    "    LISTINGS_PATH = '../data/listings.parquet'\n",
    "    MODEL_PATH = '../data/xgboost_model_optimized'\n",
    "\"\"\")\n",
    "\n",
    "for param, value in search.best_params_.items():\n",
    "    param_upper = param.upper()\n",
    "    if isinstance(value, float):\n",
    "        print(f\"    {param_upper} = {value}\")\n",
    "    else:\n",
    "        print(f\"    {param_upper} = {value}\")\n",
    "\n",
    "print(\"\"\"    RANDOM_STATE = 42\n",
    "    \n",
    "    # Cross-Validation Results\"\"\")\n",
    "print(f\"    # CV RMSE: {best_cv_rmse:.4f} (Â±{cv_results.loc[best_idx, 'std_test_score']:.4f})\")\n",
    "print(f\"    # Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"    # Improvement: {improvement:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce25d13a",
   "metadata": {},
   "source": [
    "# Visualize Hyperparameter Search Results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPERPARAMETER SEARCH VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Learning Rate vs RMSE\n",
    "if 'param_learning_rate' in cv_results.columns:\n",
    "    ax1 = axes[0, 0]\n",
    "    lr_results = cv_results.groupby('param_learning_rate')['mean_rmse'].agg(['mean', 'std'])\n",
    "    ax1.bar(range(len(lr_results)), lr_results['mean'], yerr=lr_results['std'],\n",
    "            color='steelblue', capsize=5, alpha=0.8)\n",
    "    ax1.set_xticks(range(len(lr_results)))\n",
    "    ax1.set_xticklabels([f'{x:.2f}' for x in lr_results.index])\n",
    "    ax1.set_xlabel('Learning Rate')\n",
    "    ax1.set_ylabel('Mean CV RMSE')\n",
    "    ax1.set_title('Learning Rate Impact on RMSE')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Max Depth vs RMSE\n",
    "if 'param_max_depth' in cv_results.columns:\n",
    "    ax2 = axes[0, 1]\n",
    "    depth_results = cv_results.groupby('param_max_depth')['mean_rmse'].agg(['mean', 'std'])\n",
    "    ax2.bar(range(len(depth_results)), depth_results['mean'], yerr=depth_results['std'],\n",
    "            color='coral', capsize=5, alpha=0.8)\n",
    "    ax2.set_xticks(range(len(depth_results)))\n",
    "    ax2.set_xticklabels([str(int(x)) for x in depth_results.index])\n",
    "    ax2.set_xlabel('Max Depth')\n",
    "    ax2.set_ylabel('Mean CV RMSE')\n",
    "    ax2.set_title('Max Depth Impact on RMSE')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. N Estimators vs RMSE\n",
    "if 'param_n_estimators' in cv_results.columns:\n",
    "    ax3 = axes[1, 0]\n",
    "    est_results = cv_results.groupby('param_n_estimators')['mean_rmse'].agg(['mean', 'std'])\n",
    "    ax3.bar(range(len(est_results)), est_results['mean'], yerr=est_results['std'],\n",
    "            color='seagreen', capsize=5, alpha=0.8)\n",
    "    ax3.set_xticks(range(len(est_results)))\n",
    "    ax3.set_xticklabels([str(int(x)) for x in est_results.index])\n",
    "    ax3.set_xlabel('N Estimators')\n",
    "    ax3.set_ylabel('Mean CV RMSE')\n",
    "    ax3.set_title('N Estimators Impact on RMSE')\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Top Configurations Comparison\n",
    "ax4 = axes[1, 1]\n",
    "top_n = min(10, len(cv_results_sorted))\n",
    "top_configs = cv_results_sorted.head(top_n)\n",
    "colors = ['gold' if i == 0 else 'mediumpurple' for i in range(top_n)]\n",
    "bars = ax4.barh(range(top_n), top_configs['mean_rmse'], xerr=top_configs['std_rmse'],\n",
    "                color=colors, capsize=3, alpha=0.8)\n",
    "ax4.set_yticks(range(top_n))\n",
    "ax4.set_yticklabels([f\"Config {i + 1}\" for i in range(top_n)])\n",
    "ax4.set_xlabel('CV RMSE')\n",
    "ax4.set_title(f'Top {top_n} Configurations (Gold = Best)')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (rmse, std) in enumerate(zip(top_configs['mean_rmse'], top_configs['std_rmse'])):\n",
    "    ax4.text(rmse + std + 0.01, i, f'{rmse:.4f}', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "viz_path = f\"{optimized_model_path}/hyperparameter_search_results.png\"\n",
    "plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Visualization saved to: {viz_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60def28480728a43",
   "metadata": {},
   "source": [
    "# [BASELINE] Train XGBoost Model with Config Parameters\n",
    "# Note: This cell uses the manual Config parameters as baseline.\n",
    "# For optimized parameters, see cells 6-10 above which use GridSearchCV.\n",
    "print(\"\\n[BASELINE] Training XGBoost model with Config parameters...\")\n",
    "\n",
    "# Create validation set for monitoring\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=config.VALIDATION_SIZE,\n",
    "    random_state=config.RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"  - Training set: {X_train_split.shape[0]:,} samples\")\n",
    "print(f\"  - Validation set: {X_val_split.shape[0]:,} samples\")\n",
    "\n",
    "# XGBoost 3.x sklearn API\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=config.N_ESTIMATORS,\n",
    "    max_depth=config.MAX_DEPTH,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    subsample=config.SUBSAMPLE,\n",
    "    colsample_bytree=config.COL_SAMPLE_BY_TREE,\n",
    "    min_child_weight=config.MIN_CHILD_WEIGHT,\n",
    "    gamma=config.GAMMA,\n",
    "    reg_alpha=config.REG_ALPHA,\n",
    "    reg_lambda=config.REG_LAMBDA,\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    objective='reg:squarederror',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_pred = model.predict(X_val_split)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val_split, val_pred))\n",
    "print(f\"  - Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "print(f\"âœ“ Model trained successfully ({config.N_ESTIMATORS} iterations)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "948033f970bd6b5e",
   "metadata": {},
   "source": [
    "# Generate Predictions (uses optimized model from cell 8)\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Clip predictions to valid rating range [1, 5]\n",
    "y_pred = np.clip(y_pred, 1.0, 5.0)\n",
    "\n",
    "# Create predictions DataFrame for display\n",
    "predictions_df = pd.DataFrame({\n",
    "    'user_id': test_df['user_id'].values,\n",
    "    'item_id': test_df['item_id'].values,\n",
    "    'rating': y_test,\n",
    "    'prediction': y_pred\n",
    "})\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(predictions_df.head(10).to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bcb7b6b",
   "metadata": {},
   "source": [
    "# Calculate RMSE and Display Feature Importance\n",
    "print(\"\\nCalculating final metrics...\")\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "# Contextual Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"On average, the model's prediction is off by {rmse:.2f} stars.\")\n",
    "if rmse < 1.0:\n",
    "    print(f\"âœ“ Excellent! RMSE is below 1.0, which is considered good for a 5-star scale.\")\n",
    "else:\n",
    "    print(f\"For a 5-star scale, an RMSE below 1.0 is generally considered acceptable for a baseline.\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Calculate additional metrics\n",
    "print(\"\\nAdditional Metrics:\")\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Rating: {np.mean(y_test):.4f}\")\n",
    "print(f\"Std Rating: {np.std(y_test):.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2cefbdf5",
   "metadata": {},
   "source": [
    "# Save the OPTIMIZED model for future use\n",
    "print(f\"\\nSaving optimized model to {optimized_model_path}...\")\n",
    "os.makedirs(optimized_model_path, exist_ok=True)\n",
    "model.save_model(f\"{optimized_model_path}/xgboost_model.json\")\n",
    "\n",
    "# Save feature importance for optimized model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Save comprehensive model info with CV results\n",
    "model_info = {\n",
    "    'feature_names': available_features,\n",
    "    'categorical_columns': list(label_encoders.keys()),\n",
    "    'test_rmse': float(rmse),\n",
    "    'test_mae': float(mae),\n",
    "    'cv_rmse': float(best_cv_rmse),\n",
    "    'cv_std': float(cv_results.loc[best_idx, 'std_test_score']),\n",
    "    'n_features': len(available_features),\n",
    "    'optimal_hyperparameters': search.best_params_,\n",
    "    'search_info': {\n",
    "        'method': 'RandomizedSearchCV' if USE_RANDOMIZED_SEARCH else 'GridSearchCV',\n",
    "        'cv_folds': CV_FOLDS,\n",
    "        'n_iterations': N_ITER_RANDOM if USE_RANDOMIZED_SEARCH else 'full_grid',\n",
    "        'duration_seconds': duration\n",
    "    },\n",
    "    'comparison': {\n",
    "        'baseline_rmse': baseline_rmse,\n",
    "        'improvement_percent': float(improvement)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{optimized_model_path}/model_info.json\", 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv(f\"{optimized_model_path}/feature_importance.csv\", index=False)\n",
    "\n",
    "# Save CV results\n",
    "cv_results_sorted.to_csv(f\"{optimized_model_path}/cv_results.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ Optimized model saved successfully\")\n",
    "print(f\"  - Model: {optimized_model_path}/xgboost_model.json\")\n",
    "print(f\"  - Config: {optimized_model_path}/optimal_config.json\")\n",
    "print(f\"  - Info: {optimized_model_path}/model_info.json\")\n",
    "print(f\"  - Feature importance: {optimized_model_path}/feature_importance.csv\")\n",
    "print(f\"  - CV results: {optimized_model_path}/cv_results.csv\")\n",
    "print(f\"  - Visualization: {optimized_model_path}/hyperparameter_search_results.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
